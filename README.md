# üéÆüé≤ Replicaci√≥n y Alta Disponibilidad en un Juego de Apuestas en Tiempo Real

## üìå Introducci√≥n

Este proyecto consiste en el dise√±o e implementaci√≥n de una aplicaci√≥n distribuida que simula una **sala de apuestas en tiempo real**, inspirada en el juego _Aviator_.
El objetivo principal es garantizar la **alta disponibilidad** y la **consistencia de los datos** mediante un **cl√∫ster de bases de datos replicado** y un sistema tolerante a fallos en el backend.

La aplicaci√≥n permite que, aunque un nodo de la base de datos o del backend falle, el sistema siga operativo mediante **failover autom√°tico** y **reconexiones transparentes** para el usuario.

## ‚öôÔ∏è Tecnolog√≠as

- **Backend:** Node.js
- **Frontend:** React + TypeScript
- **Base de datos:** MongoDB replicado (3 nodos ‚Äì Maestro/Esclavos)
- **Comunicaci√≥n en tiempo real:** WebSockets
- **Balanceo de carga:** Nginx
- **Gesti√≥n de estado distribuido:** Redis (Pub/Sub)
- **Contenedores y despliegue:** Docker & Docker Compose

## üéØ Objetivos del Laboratorio

1. **Arquitectura Distribuida**

   - Dise√±o de un sistema con nodos de backend, frontend y base de datos replicada.

2. **Replicaci√≥n y Failover de Base de Datos**

   - Configurar replicaci√≥n Maestro‚ÄìEsclavo en MongoDB.
   - Promoci√≥n autom√°tica de un esclavo cuando el maestro cae.

3. **Backend (API de Apuestas)**

   - Gesti√≥n de l√≥gica del juego.
   - Escrituras ‚Üí Maestro | Lecturas ‚Üí Esclavos.

4. **Frontend (Sala en Tiempo Real)**

   - Interfaz de usuario donde los jugadores realizan apuestas.
   - Comunicaci√≥n en tiempo real con WebSockets.

5. **Alta Disponibilidad del Backend**

   - Balanceo de carga con Nginx.
   - Redis Pub/Sub para compartir estado entre nodos.
   - Reconexi√≥n autom√°tica de WebSockets en el cliente.

## üìã Arquitectura

```
                        ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
                        ‚îÇ     Cliente Web     ‚îÇ
                        ‚îÇ  React + TypeScript ‚îÇ
                        ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                                  ‚îÇ
                                  ‚ñº
                        ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
                        ‚îÇ  Nginx Load Balancer‚îÇ
                        ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                   ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
                   ‚ñº                             ‚ñº
        ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê            ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
        ‚îÇ   Backend Node.js ‚îÇ            ‚îÇ   Backend Node.js ‚îÇ
        ‚îÇ   Express + WS    ‚îÇ‚óÄ‚îÄ‚îÄRedis‚îÄ‚îÄ‚ñ∂|   Express + WS    ‚îÇ
        ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò            ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                  |‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                  |
                  ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
|  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê   ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê   ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    |
|  ‚îÇ   MongoDB (Master)  ‚îÇ‚îÄ‚îÄ‚îÄ|   MongoDB (Slave)   ‚îÇ‚îÄ‚îÄ‚îÄ‚îÇ   MongoDB (Slave)   ‚îÇ    |
|  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò   ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò   ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    |
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò


```

### Componentes:

- **NGINX**: Balanceador de carga para distribuir conexiones WebSocket
- **Backend 1 y 2**: Instancias Node.js con Socket.IO
- **Redis**: Estado compartido y Pub/Sub para sincronizaci√≥n
- **MongoDB Replica Set**: 3 nodos para alta disponibilidad de datos

---

## üöÄ Despliegue R√°pido

### Prerrequisitos

- Docker y Docker Compose instalados
- Puertos libres: 80, 3001, 3002, 6379, 27017-27019

### Paso 1: Clonar repositorio

### Paso 2: Iniciar servicios con Docker Compose

```bash
docker-compose up --build -d
```

Esto levantar√°:

- 3 nodos MongoDB (replica set)
- 1 nodo Redis
- 2 backends Node.js
- 1 NGINX como load balancer

### Paso 3: Inicializar Replica Set de MongoDB

Esperar 10 segundos y luego ejecutar:

```bash
docker exec -it aviator-mongo1 mongosh --eval "
rs.initiate({
  _id: 'aviator-rs',
  members: [
    { _id: 0, host: 'aviator-mongo1:27017', priority: 3 },
    { _id: 1, host: 'aviator-mongo2:27017', priority: 2 },
    { _id: 2, host: 'aviator-mongo3:27017', priority: 1 }
  ]
})
"
```

Verificar el estado del replica set:

```bash
docker exec -it aviator-mongo1 mongosh --eval "rs.status()"
```

Deber√≠as ver un nodo PRIMARY y dos SECONDARY.

### Paso 4: Verificar logs

```bash
# Ver logs de los backends
docker-compose logs -f backend1 backend2

# Deber√≠as ver:
# [backend1] üëë SOY EL L√çDER
# [backend2] üì° Modo seguidor
```

### Paso 5: Acceder al frontend

Abre el frontend en el navegador, para esto tines que ir a frontend y hacer `npm i` y luego `npm run dev`

---

## üß™ Pruebas de Alta Disponibilidad

### Prueba 1: Failover del Backend

1. Abre varios navegadores y conecta m√∫ltiples usuarios
2. Verifica que todos vean las apuestas en tiempo real
3. Det√©n el backend l√≠der:

```bash
docker stop aviator-backend1
```

4. **Resultado esperado**:

   - Los clientes conectados a backend1 se desconectan moment√°neamente
   - El frontend reconecta autom√°ticamente a trav√©s de NGINX
   - Backend2 se convierte en l√≠der autom√°ticamente
   - El juego contin√∫a sin p√©rdida de datos

5. Verificar logs de backend2:

```bash
docker logs aviator-backend2
# Deber√≠as ver: [backend2] üëë SOY EL L√çDER
```

6. Reiniciar backend1:

```bash
docker start aviator-backend1
```

### Prueba 2: Failover de MongoDB

1. Con el juego funcionando, verificar el nodo PRIMARY:

```bash
docker exec -it aviator-mongo1 mongosh --eval "rs.status()" | grep -A 2 PRIMARY
```

2. Detener el nodo PRIMARY (asumiendo que es mongo1):

```bash
docker stop aviator-mongo1
```

3. **Resultado esperado**:

   - MongoDB autom√°ticamente elige un nuevo PRIMARY
   - Los backends reconectan autom√°ticamente
   - El juego contin√∫a sin interrupciones

4. Verificar nueva configuraci√≥n:

```bash
docker exec -it aviator-mongo2 mongosh --eval "rs.status()"
```

5. Reiniciar mongo1:

```bash
docker start aviator-mongo1
```

---

## üìä Monitoreo

### Ver estado de Redis

```bash
docker exec -it aviator-redis redis-cli

# Comandos √∫tiles:
KEYS *                    # Ver todas las claves
GET game:leader           # Ver qui√©n es el l√≠der
GET game:round:current    # Ver ronda actual
KEYS player:*             # Ver jugadores conectados
```

### Ver estado de MongoDB

```bash
docker exec -it aviator-mongo1 mongosh

use aviator
db.users.find()           // Ver usuarios
db.gamerounds.find().sort({roundNumber:-1}).limit(5)  // √öltimas 5 rondas
```

### Ver logs en tiempo real

```bash
# Todos los servicios
docker-compose logs -f

# Solo backends
docker-compose logs -f backend1 backend2

# Solo MongoDB
docker-compose logs -f mongo1 mongo2 mongo3
```

---

## üõë Detener el sistema

```bash
# Detener todos los servicios
docker-compose down

# Detener y eliminar vol√∫menes (‚ö†Ô∏è borra todos los datos)
docker-compose down -v
```

---

## üêõ Troubleshooting

### Backend no se conecta a MongoDB

```bash
# Verificar que el replica set est√© configurado
docker exec -it aviator-mongo1 mongosh --eval "rs.status()"

# Reinicializar si es necesario
docker exec -it aviator-mongo1 mongosh --eval "rs.reconfig(...)"
```

### Redis no responde

```bash
# Verificar estado
docker exec -it aviator-redis redis-cli ping

# Deber√≠a responder: PONG
```

### WebSocket no conecta

```bash
# Verificar que NGINX est√© corriendo
docker ps | grep nginx

# Ver logs de NGINX
docker logs aviator-nginx

# Verificar configuraci√≥n
docker exec -it aviator-nginx cat /etc/nginx/nginx.conf
```

### Frontend no sincroniza

1. Abrir consola del navegador (F12)
2. Verificar mensajes de Socket.IO
3. Verificar que `SERVER_URL` en `frontend/src/socket.tsx` apunte correctamente:

```typescript
const SERVER_URL = "http://localhost"; // Cambiar si es necesario
```

---

## üìù Arquitectura T√©cnica

### Flujo de una Ronda

1. **Backend L√≠der** crea nueva ronda:

   - Genera `crashPoint` aleatorio
   - Calcula `startTime = now + 10000ms` (10 segundos para apostar)
   - Calcula `crashTime = startTime + duration`
   - Guarda en Redis: `game:round:current`
   - Publica evento: `game:round:new`

2. **Todos los Backends** reciben evento y notifican a sus clientes conectados

3. **Frontends** esperan hasta `startTime` y comienzan a incrementar multiplicador localmente

4. **Backend L√≠der** verifica cada 500ms si es hora de crashear

5. Cuando `now >= crashTime`:
   - L√≠der publica evento: `game:round:crash`
   - Todos los backends notifican a sus clientes
   - Se espera 3 segundos y se crea nueva ronda

### Sincronizaci√≥n de Estado

- **Redis**: Estado vol√°til (jugadores, ronda actual)
- **MongoDB**: Persistencia (usuarios, historial de rondas)
- **Pub/Sub**: Comunicaci√≥n entre backends

### Liderazgo

- El l√≠der mantiene un lock en Redis: `game:leader` con TTL de 5s
- Renueva el lock cada 3s
- Si falla, otro backend toma el liderazgo autom√°ticamente

---

## üë• Contribuciones

Para agregar nuevas funcionalidades:

1. Fork el repositorio
2. Crear feature branch: `git checkout -b feature/nueva-funcionalidad`
3. Commit cambios: `git commit -am 'Agrega nueva funcionalidad'`
4. Push a la rama: `git push origin feature/nueva-funcionalidad`
5. Crear Pull Request

---

## üìÑ Licencia

Este proyecto es para fines educativos del laboratorio de Sistemas Distribuidos.
